{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbl8BS0TxWDD"
      },
      "source": [
        "## Creating lists with multiple articles\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_CjRwS5xfmh"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "url = \"https://www.theguardian.com/international\"\n",
        "source = requests.get(url).text\n",
        "soup = BeautifulSoup(source, \"html.parser\")\n",
        "\n",
        "\n",
        "selected_categories = ['Environment',\n",
        " 'Business',\n",
        " 'Tech',\n",
        " 'Science',\n",
        " 'Soccer',\n",
        " 'NFL',\n",
        " 'Tennis',\n",
        " 'MLB',\n",
        " 'NHL',\n",
        " 'Film',\n",
        " 'Fashion',\n",
        " 'Food',\n",
        " 'Travel']\n",
        "\n",
        "# Scraping_class = \"menu-item__title\"\n",
        "# landing_page_class = \"submeta__link\" \n",
        "page_limit = 100\n",
        "\n",
        "\n",
        "\n",
        "ARTICLE_2D = []\n",
        "\n",
        "\n",
        "\n",
        "for i, element in enumerate(soup.find_all('a', href=True, class_=\"menu-item__title\")[0:40]):\n",
        "    #if the catagory exists in selected catagory\n",
        "    \n",
        " \n",
        "    if selected_categories.count(element.text.strip())>0:\n",
        "        print(f\"------------------------------------Category: {element.text.strip()}---------------------------------\") #category\n",
        "        selected_categories.remove(element.text.strip()) #To skip repeat remove considered catagory from selected\n",
        "        \n",
        "        category_source = requests.get(element['href']).text\n",
        "        print(element['href'])\n",
        "        print(\"\\n\")\n",
        "        soup_category = BeautifulSoup(category_source, 'html.parser')\n",
        "\n",
        "\n",
        "\n",
        "        #Check if \"All Today's Story\" is available\n",
        "        all_todays_story = (soup_category.find('a', class_=\"submeta__link\", attrs={\"data-link-name\":\"all\"})) #Available only for  \"All today's stories\"\n",
        "        if all_todays_story:  #if \"All today's stories\" is available then we should get into that page to scrap previous articles\n",
        "            # URL of ALL page\n",
        "            page_source = requests.get(all_todays_story['href']).text #URL of ALL page [page 1]\n",
        "            print(all_todays_story['href'])\n",
        "            # all_source = requests.get(\"\")\n",
        "\n",
        "\n",
        "            for page_i1 in range(page_limit):\n",
        "                try:\n",
        "                    # print(page_source)\n",
        "                    #Page \n",
        "                    soup_page = BeautifulSoup(page_source, \"html.parser\") #Page 1\n",
        "                    # Scrap --- ALL types pages\n",
        "                    for j, article_link in enumerate(soup_page.find_all('a', class_=\"u-faux-block-link__overlay js-headline-text\", attrs={\"data-link-name\":\"article\"})):      #all article in that page              \n",
        "\n",
        "                        source_article = requests.get(article_link['href']).text   #article link\n",
        "                        soup_article = BeautifulSoup(source_article, 'html.parser')\n",
        "\n",
        "                        article_sub_title = soup_article.find('div', class_=\"dcr-zjgnrw\", attrs={'data-gu-name':\"standfirst\"}) #subtitle\n",
        "                        article_content = soup_article.find('div', class_=\"article-body-commercial-selector article-body-viewer-selector dcr-18wsxay\")\n",
        "                        authors = soup_article.find('a', attrs={\"rel\":\"author\"})\n",
        "                        article_publication_date_time = soup_article.find('summary', class_=\"dcr-h56grb\")\n",
        "                        \n",
        "                        if article_content and authors and article_publication_date_time:\n",
        "                            ARTICLE = []\n",
        "                            ARTICLE.append(article_link.text)       #title                     \n",
        "                            ARTICLE.append(article_sub_title.text)  #subtitle\n",
        "                            ARTICLE.append(article_link['href'])        #url\n",
        "                            ARTICLE.append(authors.text)            #authors\n",
        "                            ARTICLE.append(article_publication_date_time.text)  #date\n",
        "                            ARTICLE.append(article_content.text)            #content\n",
        "                            ARTICLE.append(element.text.strip())           # category\n",
        "                            ARTICLE_2D.append(ARTICLE)\n",
        "\n",
        "                            # print(j, article_link['href']) # article link\n",
        "                            # print(article_link.text) #title\n",
        "                            # print(\"--\")\n",
        "                            # print(article_sub_title.text) #sub title \n",
        "                            # print(\"--\")\n",
        "                            # print(article_content.text) #article content\n",
        "                            # print(\"--\")\n",
        "                            # print(authors.text) # authors\n",
        "                            # print(\"--\")\n",
        "                            # print(article_publication_date_time.text) #publication date time\n",
        "                            # print(f\"Article {j} of {article_link['href']}\")\n",
        "                            # print('\\n')\n",
        "                        continue\n",
        "                # print(page_i1*j)\n",
        "\n",
        "                    # Scrap END\n",
        "\n",
        "                    next_page = soup_page.find('a', class_=\"button button--small button--tertiary pagination__action--static \", attrs={\"data-link-name\":\"Pagination view next\"}) #Page 1's next page attribute\n",
        "                    print(next_page['href'])               \n",
        "                    page_source = requests.get(next_page['href']).text\n",
        "                except Exception as e:\n",
        "                    print(e.__class__)\n",
        "                    break\n",
        "\n",
        "            print(f\"Out of All Todays Story. Total {page_i1*j}---------------------------\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        else:\n",
        "            # print(\"Landing Page is page 1\")\n",
        "            # page_source = requests.get(element['href']).text\n",
        "            page_source = requests.get(element['href']).text\n",
        "            # print(element['href'])\n",
        "\n",
        "\n",
        "\n",
        "            for page_i2 in range(page_limit):\n",
        "                try: \n",
        "                    soup_page = BeautifulSoup(page_source, \"html.parser\") #Page 1\n",
        "\n",
        "                    # Scrap --- ALL types pages\n",
        "                    for j, article_link in enumerate(soup_page.find_all('a', class_=\"u-faux-block-link__overlay js-headline-text\", attrs={\"data-link-name\":\"article\"})):                    \n",
        "\n",
        "                        source_article = requests.get(article_link['href']).text\n",
        "                        soup_article = BeautifulSoup(source_article, 'html.parser')\n",
        "\n",
        "                        article_sub_title = soup_article.find('div', class_=\"dcr-zjgnrw\", attrs={'data-gu-name':\"standfirst\"}) #subtitle\n",
        "                        article_content = soup_article.find('div', class_=\"article-body-commercial-selector article-body-viewer-selector dcr-18wsxay\")\n",
        "                        authors = soup_article.find('a', attrs={\"rel\":\"author\"})\n",
        "                        article_publication_date_time = soup_article.find('summary', class_=\"dcr-h56grb\")\n",
        "                        \n",
        "                        if article_content and authors and article_publication_date_time:\n",
        "                            # TITLE.append(article_link.text)\n",
        "                            # SUBTITLE.append(article_sub_title.text)\n",
        "                            # URL.append(article_link['href'])\n",
        "                            # AUTHORS.append(authors.text)\n",
        "                            # PUBLICATION_DATE.append(article_publication_date_time.text)\n",
        "                            # CONTENT.append(article_content.text)\n",
        "                            # CATEGORY.append(element.text.strip())\n",
        "\n",
        "                            ARTICLE = []\n",
        "                            ARTICLE.append(article_link.text)       #title                     \n",
        "                            ARTICLE.append(article_sub_title.text)  #subtitle\n",
        "                            ARTICLE.append(article_link['href'])        #url\n",
        "                            ARTICLE.append(authors.text)            #authors\n",
        "                            ARTICLE.append(article_publication_date_time.text)  #date\n",
        "                            ARTICLE.append(article_content.text)            #content\n",
        "                            ARTICLE.append(element.text.strip())           # category\n",
        "                            ARTICLE_2D.append(ARTICLE)\n",
        "\n",
        "                            # print(j, article_link['href']) #link\n",
        "                            # print(article_link.text) #title\n",
        "                            # print(\"--\")\n",
        "                            # print(article_sub_title.text)\n",
        "                            # print(\"--\")\n",
        "                            # print(article_content.text)\n",
        "                            # print(\"--\")\n",
        "                            # print(authors.text)\n",
        "                            # print(\"--\")\n",
        "                            # print(article_publication_date_time.text)\n",
        "                        # print(f\"Article {j} of {article_link['href']}\")\n",
        "                            # print('\\n')\n",
        "                        continue\n",
        "                    # Scrap\n",
        "                    next_page = soup_page.find('a', class_=\"button button--small button--tertiary pagination__action--static \", attrs={\"data-link-name\":\"Pagination view next\"}) #Page 1's next page attribute\n",
        "                    # print(soup_page)\n",
        "                    print(next_page['href'])\n",
        "                    # break\n",
        "                    page_source = requests.get(next_page['href']).text\n",
        "                except Exception as e:\n",
        "                    print(e.__class__)\n",
        "                    break\n",
        "            print(f\"Out of Individual Page. Total: {page_i2*j}-------------------------\")\n",
        "\n",
        "selected_categories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLxfTe-Blull"
      },
      "source": [
        "## Parsing for Food & Travel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bpEKO86VqDv",
        "outputId": "f78d6e07-84be-4ab7-9189-f48282aabfcc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15495"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "len(ARTICLE_2D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOY8BuYImXXJ",
        "outputId": "53e0263d-8157-4972-c3e8-2e6588e0d70c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13098"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Copy 2D list\n",
        "Saved_ARTICLE_2D = ARTICLE_2D.copy()\n",
        "len(Saved_ARTICLE_2D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AU671TVMXpkm"
      },
      "outputs": [],
      "source": [
        "HEADERS = [\"TITLE\", \"SUBTITLE\", \"URL\", \"AUTHORS\", \"PUBLICATION DATE TIME\", \"CONTENT\", \"CATEGORY\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqpqMupnpGQ1"
      },
      "source": [
        "# Exporting to SQL, CSV, Excel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqJ86W0Ir191"
      },
      "source": [
        "## Crawler to SQLite Database "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNIJq9aVpEl-"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "# Connect/Create database\n",
        "connection = sqlite3.connect('The_Guardian_Database.db')\n",
        "# Create cursor object to create database table further\n",
        "cursor = connection.cursor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeornt5qpl9n",
        "outputId": "1245039d-df4b-4a27-f37a-edbb81585039"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<sqlite3.Cursor at 0x7f98ace81880>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Create Table\n",
        "# HEADERS = [\"TITLE\", \"SUBTITLE\", \"URL\", \"AUTHORS\", \"PUBLICATION DATE TIME\", \"CONTENT\", \"CATEGORY\"]\n",
        "cursor.execute('''CREATE TABLE IF NOT EXISTS Article\n",
        " ('TITLE' TEXT NOT NULL,\n",
        " 'SUBTITLE' TEXT,\n",
        " 'URL' TEXT NOT NULL, \n",
        " 'AUTHORS' TEXT,\n",
        " 'PUBLICATION DATE TIME' TEXT,\n",
        " 'CONTENT' TEXT,\n",
        " 'CATEGORY' TEXT,\n",
        " \n",
        " PRIMARY KEY ('URL'))''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcvEM5vppnTD"
      },
      "outputs": [],
      "source": [
        "# print(f\"Total Header: {len(HEADERS)}\") \n",
        "# print(f\"Total entry of a Company: {len(AR[1])}\")\n",
        "# print(f\"Total Company: {len(COLUMNS)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwXw5CGxqETy"
      },
      "outputs": [],
      "source": [
        "#  INSERT Multiple 2D List into SQLite DB\n",
        "# ? MARK will be equal to HEADERS\n",
        "sql_statement = 'INSERT OR IGNORE INTO Article VALUES (?,?,?,?,?,?,?)'\n",
        "cursor.executemany(sql_statement, ARTICLE_2D)\n",
        "for rows in cursor.execute(\"SELECT * FROM Article\"):\n",
        "    print(rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUc97gMDqHay"
      },
      "outputs": [],
      "source": [
        "connection.commit()\n",
        "connection.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwUtkFjqGhRY"
      },
      "source": [
        "## SQLite to CSV & EXCEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FE_WpHBGoDM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Connect/Create database\n",
        "connection = sqlite3.connect('The_Guardian_Database.db')\n",
        "# Create cursor object to create database table further\n",
        "cursor = connection.cursor()\n",
        "\n",
        "sql_query  = pd.read_sql_query('''SELECT * FROM Article''', connection)\n",
        "\n",
        "df_from_sql = pd.DataFrame(sql_query, columns = HEADERS)\n",
        "connection.close() # Closing connection\n",
        "\n",
        "# Exporting dataframe to CSV\n",
        "df_from_sql.to_csv('The_Guardian_Articles_SQL_Taufiq.csv', index=False)\n",
        "df_from_sql.to_excel(\"The_Guardian_Articles_Taufiq_SQL.xlsx\", index=False)\n",
        "\n",
        "df_from_sql\n",
        "\n",
        "# # Creating dataframe from above lists\n",
        "# df = pd.DataFrame(COMPANY_DATA_2D, columns=HEADER)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpmVNlUWE1ZJ"
      },
      "source": [
        "# DEBUG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lYA5oAioOMg"
      },
      "source": [
        "## Data Frame -- EXPERIMENT purpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "gdQYyO2wn5C2",
        "outputId": "146d9c6d-baa4-4dbf-93a8-0630f602ef8f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4b1d5a40-fa83-4567-8f88-471bc3ea9bf9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TITLE</th>\n",
              "      <th>SUBTITLE</th>\n",
              "      <th>URL</th>\n",
              "      <th>AUTHORS</th>\n",
              "      <th>PUBLICATION DATE TIME</th>\n",
              "      <th>CONTENT</th>\n",
              "      <th>CATEGORY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M&amp;S stops selling disposable barbecues in UK s...</td>\n",
              "      <td>Retailer removes items from its shops to ‘prot...</td>\n",
              "      <td>https://www.theguardian.com/business/2022/aug/...</td>\n",
              "      <td>Joe Middleton</td>\n",
              "      <td>Wed 3 Aug 2022 13.58 EDT</td>\n",
              "      <td>Marks &amp; Spencer has removed disposable barbecu...</td>\n",
              "      <td>Environment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Unions call for Victoria’s proposed laws targe...</td>\n",
              "      <td>In letter to Daniel Andrews, union groups argu...</td>\n",
              "      <td>https://www.theguardian.com/australia-news/202...</td>\n",
              "      <td>Adeshola Ore</td>\n",
              "      <td>Wed 3 Aug 2022 13.30 EDT</td>\n",
              "      <td>A group of unions have hit out at the Andrews ...</td>\n",
              "      <td>Environment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Record coral cover on parts of Great Barrier R...</td>\n",
              "      <td>Fast-growing species of branching and plate-li...</td>\n",
              "      <td>https://www.theguardian.com/environment/2022/a...</td>\n",
              "      <td>Graham Readfearn</td>\n",
              "      <td>Wed 3 Aug 2022 13.30 EDT</td>\n",
              "      <td>Marine scientists monitoring the Great Barrier...</td>\n",
              "      <td>Environment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>John Howard’s climate doubts reveal more about...</td>\n",
              "      <td>The latest comments from the former PM, who on...</td>\n",
              "      <td>https://www.theguardian.com/environment/2022/a...</td>\n",
              "      <td>Graham Readfearn</td>\n",
              "      <td>Wed 3 Aug 2022 13.30 EDT</td>\n",
              "      <td>The former prime minister John Howard remains ...</td>\n",
              "      <td>Environment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>‘Nothing off the table’ in bid to deliver 450G...</td>\n",
              "      <td>Tanya Plibersek accuses the Coalition of preve...</td>\n",
              "      <td>https://www.theguardian.com/australia-news/202...</td>\n",
              "      <td>Tory Shepherd</td>\n",
              "      <td>Wed 3 Aug 2022 13.30 EDT</td>\n",
              "      <td>Nothing is off the table in the battle to deli...</td>\n",
              "      <td>Environment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15490</th>\n",
              "      <td>Britons ignore ministers and rush to book UK s...</td>\n",
              "      <td>Holiday cottage firms and campsites see ‘stamp...</td>\n",
              "      <td>https://www.theguardian.com/travel/2021/feb/12...</td>\n",
              "      <td>Isabel Choat</td>\n",
              "      <td>Fri 12 Feb 2021 12.27 EST</td>\n",
              "      <td>A day is a long time in the pandemic. On Wedne...</td>\n",
              "      <td>Travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15491</th>\n",
              "      <td>Lastminute.com faces legal action unless it re...</td>\n",
              "      <td>Covid-affected customers must be paid back wit...</td>\n",
              "      <td>https://www.theguardian.com/business/2021/feb/...</td>\n",
              "      <td>Mark Sweney</td>\n",
              "      <td>Fri 12 Feb 2021 05.47 EST</td>\n",
              "      <td>The UK competition watchdog has said it will t...</td>\n",
              "      <td>Travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15492</th>\n",
              "      <td>Minister defends England's softer hotel quaran...</td>\n",
              "      <td>English system less stringent than Australia’s...</td>\n",
              "      <td>https://www.theguardian.com/world/2021/feb/12/...</td>\n",
              "      <td>Haroon Siddique</td>\n",
              "      <td>Fri 12 Feb 2021 05.27 EST</td>\n",
              "      <td>A government minister has defended the rules i...</td>\n",
              "      <td>Travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15493</th>\n",
              "      <td>Samba and caipirinhas: how to celebrate Rio’s ...</td>\n",
              "      <td>The world’s biggest party should have started ...</td>\n",
              "      <td>https://www.theguardian.com/travel/2021/feb/12...</td>\n",
              "      <td>Gavin McOwan</td>\n",
              "      <td>Fri 12 Feb 2021 01.30 EST</td>\n",
              "      <td>For millions of people around the world, this ...</td>\n",
              "      <td>Travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15494</th>\n",
              "      <td>'We cannot live like this for ever': readers o...</td>\n",
              "      <td>Four Britons on the pros and cons of taking tr...</td>\n",
              "      <td>https://www.theguardian.com/travel/2021/feb/11...</td>\n",
              "      <td>Jedidajah Otte</td>\n",
              "      <td>Thu 11 Feb 2021 12.56 EST</td>\n",
              "      <td>Amid confusing messaging from the government o...</td>\n",
              "      <td>Travel</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15495 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b1d5a40-fa83-4567-8f88-471bc3ea9bf9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b1d5a40-fa83-4567-8f88-471bc3ea9bf9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b1d5a40-fa83-4567-8f88-471bc3ea9bf9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   TITLE  \\\n",
              "0      M&S stops selling disposable barbecues in UK s...   \n",
              "1      Unions call for Victoria’s proposed laws targe...   \n",
              "2      Record coral cover on parts of Great Barrier R...   \n",
              "3      John Howard’s climate doubts reveal more about...   \n",
              "4      ‘Nothing off the table’ in bid to deliver 450G...   \n",
              "...                                                  ...   \n",
              "15490  Britons ignore ministers and rush to book UK s...   \n",
              "15491  Lastminute.com faces legal action unless it re...   \n",
              "15492  Minister defends England's softer hotel quaran...   \n",
              "15493  Samba and caipirinhas: how to celebrate Rio’s ...   \n",
              "15494  'We cannot live like this for ever': readers o...   \n",
              "\n",
              "                                                SUBTITLE  \\\n",
              "0      Retailer removes items from its shops to ‘prot...   \n",
              "1      In letter to Daniel Andrews, union groups argu...   \n",
              "2      Fast-growing species of branching and plate-li...   \n",
              "3      The latest comments from the former PM, who on...   \n",
              "4      Tanya Plibersek accuses the Coalition of preve...   \n",
              "...                                                  ...   \n",
              "15490  Holiday cottage firms and campsites see ‘stamp...   \n",
              "15491  Covid-affected customers must be paid back wit...   \n",
              "15492  English system less stringent than Australia’s...   \n",
              "15493  The world’s biggest party should have started ...   \n",
              "15494  Four Britons on the pros and cons of taking tr...   \n",
              "\n",
              "                                                     URL           AUTHORS  \\\n",
              "0      https://www.theguardian.com/business/2022/aug/...     Joe Middleton   \n",
              "1      https://www.theguardian.com/australia-news/202...      Adeshola Ore   \n",
              "2      https://www.theguardian.com/environment/2022/a...  Graham Readfearn   \n",
              "3      https://www.theguardian.com/environment/2022/a...  Graham Readfearn   \n",
              "4      https://www.theguardian.com/australia-news/202...     Tory Shepherd   \n",
              "...                                                  ...               ...   \n",
              "15490  https://www.theguardian.com/travel/2021/feb/12...      Isabel Choat   \n",
              "15491  https://www.theguardian.com/business/2021/feb/...       Mark Sweney   \n",
              "15492  https://www.theguardian.com/world/2021/feb/12/...   Haroon Siddique   \n",
              "15493  https://www.theguardian.com/travel/2021/feb/12...      Gavin McOwan   \n",
              "15494  https://www.theguardian.com/travel/2021/feb/11...    Jedidajah Otte   \n",
              "\n",
              "           PUBLICATION DATE TIME  \\\n",
              "0       Wed 3 Aug 2022 13.58 EDT   \n",
              "1       Wed 3 Aug 2022 13.30 EDT   \n",
              "2       Wed 3 Aug 2022 13.30 EDT   \n",
              "3       Wed 3 Aug 2022 13.30 EDT   \n",
              "4       Wed 3 Aug 2022 13.30 EDT   \n",
              "...                          ...   \n",
              "15490  Fri 12 Feb 2021 12.27 EST   \n",
              "15491  Fri 12 Feb 2021 05.47 EST   \n",
              "15492  Fri 12 Feb 2021 05.27 EST   \n",
              "15493  Fri 12 Feb 2021 01.30 EST   \n",
              "15494  Thu 11 Feb 2021 12.56 EST   \n",
              "\n",
              "                                                 CONTENT     CATEGORY  \n",
              "0      Marks & Spencer has removed disposable barbecu...  Environment  \n",
              "1      A group of unions have hit out at the Andrews ...  Environment  \n",
              "2      Marine scientists monitoring the Great Barrier...  Environment  \n",
              "3      The former prime minister John Howard remains ...  Environment  \n",
              "4      Nothing is off the table in the battle to deli...  Environment  \n",
              "...                                                  ...          ...  \n",
              "15490  A day is a long time in the pandemic. On Wedne...       Travel  \n",
              "15491  The UK competition watchdog has said it will t...       Travel  \n",
              "15492  A government minister has defended the rules i...       Travel  \n",
              "15493  For millions of people around the world, this ...       Travel  \n",
              "15494  Amid confusing messaging from the government o...       Travel  \n",
              "\n",
              "[15495 rows x 7 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # Creating dataframe from above lists\n",
        "import pandas as pd\n",
        "# df = pd.DataFrame(2D_Data_List, columns=HEADER_List)\n",
        "# df\n",
        "df2 = pd.DataFrame(ARTICLE_2D, columns=HEADERS)\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxklfns0k-Y2"
      },
      "outputs": [],
      "source": [
        "df2.to_csv('The_Guardian_Articles_Taufiq_13category.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Crawler.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "3b756789cf4ecdfc0242dcd8e6359d57179847163f2eb06f7e55a116e9231053"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
